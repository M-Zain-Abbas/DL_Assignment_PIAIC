{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Compresive Strength Concrete Problem\n",
    "\n",
    "\n",
    "### Abstract: \n",
    "\n",
    "Concrete is the most important material in civil engineering. The concrete compressive strength (concrete strength to bear the load) is a highly nonlinear function of age and ingredients.  <br><br>\n",
    "\n",
    "<table border=\"1\"  cellpadding=\"6\" bordercolor=\"red\">\n",
    "\t<tbody>\n",
    "        <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">1030</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Physical</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
    "            <td><p class=\"normal\">Real</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
    "            <td><p class=\"normal\">9</p></td>\n",
    "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
    "            <td><p class=\"normal\">2007-08-03</p></td>\n",
    "        </tr>\n",
    "     </tbody>\n",
    "    </table>\n",
    "<table border=\"1\" cellpadding=\"6\">\t\n",
    "    <tbody>\n",
    "    <tr>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">Regression</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
    "\t\t<td><p class=\"normal\">N/A</p></td>\n",
    "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
    "\t\t<td><p class=\"normal\">231464</p></td>\n",
    "\t</tr>\n",
    "    </tbody>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Description:\n",
    "| Features Name | Data Type | Measurement | Description |\n",
    "| -- | -- | -- | -- |\n",
    "Cement (component 1) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Blast Furnace Slag (component 2) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Fly Ash (component 3) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Water (component 4) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Superplasticizer (component 5) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Coarse Aggregate (component 6) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Fine Aggregate (component 7) | quantitative | kg in a m3 mixture | Input Variable\n",
    "Age | quantitative | Day (1~365) | Input Variable\n",
    "Concrete compressive strength | quantitative | MPa | Output Variable\n",
    "\n",
    "### WORKFLOW :\n",
    "- Load Data\n",
    "- Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
    "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
    "- Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "- Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "- Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
    "- Train the Model with Epochs (100) and validate it\n",
    "- If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
    "- Evaluation Step\n",
    "- Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data:\n",
    "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/compresive_strength_concrete.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data = pd.read_csv(\"compresive_strength_concrete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9270"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#concrete_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Cement (component 1)(kg in a m^3 mixture)',\n",
       "       'Blast Furnace Slag (component 2)(kg in a m^3 mixture)',\n",
       "       'Fly Ash (component 3)(kg in a m^3 mixture)',\n",
       "       'Water  (component 4)(kg in a m^3 mixture)',\n",
       "       'Superplasticizer (component 5)(kg in a m^3 mixture)',\n",
       "       'Coarse Aggregate  (component 6)(kg in a m^3 mixture)',\n",
       "       'Fine Aggregate (component 7)(kg in a m^3 mixture)', 'Age (day)',\n",
       "       'Concrete compressive strength(MPa, megapascals) '],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#concrete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "concrete_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = concrete_data.sample(frac=0.5, random_state=0)\n",
    "concrete_data = concrete_data.drop(train_data.index)\n",
    "train_total= train_data.drop(columns=['Concrete compressive strength(MPa, megapascals) '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_data['Concrete compressive strength(MPa, megapascals) ']\n",
    "val_data = concrete_data.sample(frac=0.5, random_state=0)\n",
    "test = concrete_data.drop(val_data.index)\n",
    "val_total= val_data.drop(columns=['Concrete compressive strength(MPa, megapascals) '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label = val_data['Concrete compressive strength(MPa, megapascals) ']\n",
    "test_label = test['Concrete compressive strength(MPa, megapascals) ']\n",
    "test_total= test.drop(columns=['Concrete compressive strength(MPa, megapascals) '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_total.mean(axis=0)\n",
    "train_total -= mean\n",
    "std = train_total.std(axis=0)\n",
    "train_total /= std\n",
    "test_total /= std\n",
    "val_total/=std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "747    26.06\n",
       "718    10.35\n",
       "175    79.30\n",
       "828    74.99\n",
       "713     9.69\n",
       "       ...  \n",
       "354    30.45\n",
       "654    24.29\n",
       "460    49.99\n",
       "22      8.06\n",
       "374    16.28\n",
       "Name: Concrete compressive strength(MPa, megapascals) , Length: 515, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "#train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_label = train_label.mean()\n",
    "train_label -= mean_label\n",
    "std_label = train_label.std()\n",
    "train_label /= std_label\n",
    "test_label /= std_label\n",
    "val_label /=std_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train_total.iloc[:])\n",
    "test = np.array(test_total.iloc[:])\n",
    "val = np.array(val_total.iloc[:])\n",
    "test_l = np.array(test_label.astype('float32'))\n",
    "train_l = np.array(train_label.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "        layers.Dense(10, activation='tanh', input_shape = (train.shape[1],)),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(6, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "model.compile(optimizer = 'rmsprop', loss='mse' , metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "17/17 [==============================] - 3s 42ms/step - loss: 1.0555 - mae: 0.8260 - val_loss: 6.2721 - val_mae: 2.2600\n",
      "Epoch 2/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.8792 - mae: 0.7628 - val_loss: 6.2532 - val_mae: 2.2556\n",
      "Epoch 3/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.8130 - mae: 0.7453 - val_loss: 6.2865 - val_mae: 2.2628\n",
      "Epoch 4/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.7917 - mae: 0.7253 - val_loss: 6.3297 - val_mae: 2.2744\n",
      "Epoch 5/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.6633 - mae: 0.6692 - val_loss: 6.3834 - val_mae: 2.2905\n",
      "Epoch 6/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.6250 - mae: 0.6483 - val_loss: 6.6137 - val_mae: 2.3494\n",
      "Epoch 7/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.5443 - mae: 0.5986 - val_loss: 6.8162 - val_mae: 2.3989\n",
      "Epoch 8/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.5587 - mae: 0.6084 - val_loss: 7.2031 - val_mae: 2.4867\n",
      "Epoch 9/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.4873 - mae: 0.5670 - val_loss: 7.6711 - val_mae: 2.5860\n",
      "Epoch 10/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.4396 - mae: 0.5420 - val_loss: 8.0835 - val_mae: 2.6684\n",
      "Epoch 11/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.4174 - mae: 0.5217 - val_loss: 8.6199 - val_mae: 2.7700\n",
      "Epoch 12/120\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.3872 - mae: 0.5109 - val_loss: 9.1536 - val_mae: 2.8660\n",
      "Epoch 13/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.3579 - mae: 0.4815 - val_loss: 9.5386 - val_mae: 2.9329\n",
      "Epoch 14/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.3295 - mae: 0.4607 - val_loss: 9.6975 - val_mae: 2.9616\n",
      "Epoch 15/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3536 - mae: 0.4755 - val_loss: 10.1456 - val_mae: 3.0366\n",
      "Epoch 16/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.3337 - mae: 0.4626 - val_loss: 10.4186 - val_mae: 3.0806\n",
      "Epoch 17/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.3069 - mae: 0.4423 - val_loss: 10.6919 - val_mae: 3.1245\n",
      "Epoch 18/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2846 - mae: 0.4287 - val_loss: 10.8944 - val_mae: 3.1565\n",
      "Epoch 19/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2845 - mae: 0.4252 - val_loss: 11.1271 - val_mae: 3.1930\n",
      "Epoch 20/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2840 - mae: 0.4203 - val_loss: 11.2259 - val_mae: 3.2064\n",
      "Epoch 21/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2902 - mae: 0.4253 - val_loss: 11.5741 - val_mae: 3.2600\n",
      "Epoch 22/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2717 - mae: 0.4109 - val_loss: 11.4782 - val_mae: 3.2452\n",
      "Epoch 23/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2547 - mae: 0.3921 - val_loss: 11.6770 - val_mae: 3.2741\n",
      "Epoch 24/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2685 - mae: 0.4150 - val_loss: 11.7188 - val_mae: 3.2805\n",
      "Epoch 25/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2356 - mae: 0.3802 - val_loss: 11.6708 - val_mae: 3.2725\n",
      "Epoch 26/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2375 - mae: 0.3891 - val_loss: 11.7322 - val_mae: 3.2843\n",
      "Epoch 27/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2345 - mae: 0.3851 - val_loss: 11.8594 - val_mae: 3.3056\n",
      "Epoch 28/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.2425 - mae: 0.3901 - val_loss: 11.9504 - val_mae: 3.3183\n",
      "Epoch 29/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.2263 - mae: 0.3783 - val_loss: 11.7687 - val_mae: 3.2911\n",
      "Epoch 30/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2224 - mae: 0.3773 - val_loss: 11.8057 - val_mae: 3.2967\n",
      "Epoch 31/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2008 - mae: 0.3567 - val_loss: 11.8613 - val_mae: 3.3058\n",
      "Epoch 32/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2185 - mae: 0.3692 - val_loss: 11.5850 - val_mae: 3.2646\n",
      "Epoch 33/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.2072 - mae: 0.3482 - val_loss: 11.5133 - val_mae: 3.2538\n",
      "Epoch 34/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2125 - mae: 0.3678 - val_loss: 11.5434 - val_mae: 3.2597\n",
      "Epoch 35/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.2134 - mae: 0.3633 - val_loss: 11.3582 - val_mae: 3.2322\n",
      "Epoch 36/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2060 - mae: 0.3584 - val_loss: 11.1782 - val_mae: 3.2053\n",
      "Epoch 37/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1921 - mae: 0.3440 - val_loss: 11.5060 - val_mae: 3.2557\n",
      "Epoch 38/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1687 - mae: 0.3269 - val_loss: 11.5514 - val_mae: 3.2640\n",
      "Epoch 39/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1833 - mae: 0.3355 - val_loss: 11.5293 - val_mae: 3.2611\n",
      "Epoch 40/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1764 - mae: 0.3258 - val_loss: 11.2098 - val_mae: 3.2130\n",
      "Epoch 41/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1870 - mae: 0.3415 - val_loss: 11.3799 - val_mae: 3.2400\n",
      "Epoch 42/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.2006 - mae: 0.3531 - val_loss: 11.6102 - val_mae: 3.2762\n",
      "Epoch 43/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1899 - mae: 0.3426 - val_loss: 11.0638 - val_mae: 3.1934\n",
      "Epoch 44/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.2011 - mae: 0.3497 - val_loss: 11.1308 - val_mae: 3.2053\n",
      "Epoch 45/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1887 - mae: 0.3401 - val_loss: 10.9904 - val_mae: 3.1843\n",
      "Epoch 46/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1603 - mae: 0.3188 - val_loss: 11.1743 - val_mae: 3.2145\n",
      "Epoch 47/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1669 - mae: 0.3203 - val_loss: 11.0119 - val_mae: 3.1910\n",
      "Epoch 48/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1702 - mae: 0.3326 - val_loss: 11.0302 - val_mae: 3.1954\n",
      "Epoch 49/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1882 - mae: 0.3422 - val_loss: 10.7936 - val_mae: 3.1596\n",
      "Epoch 50/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1614 - mae: 0.3270 - val_loss: 10.5133 - val_mae: 3.1168\n",
      "Epoch 51/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1588 - mae: 0.3159 - val_loss: 10.0440 - val_mae: 3.0419\n",
      "Epoch 52/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1524 - mae: 0.3113 - val_loss: 10.0239 - val_mae: 3.0396\n",
      "Epoch 53/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1710 - mae: 0.3278 - val_loss: 10.3065 - val_mae: 3.0871\n",
      "Epoch 54/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1616 - mae: 0.3167 - val_loss: 9.7905 - val_mae: 3.0041\n",
      "Epoch 55/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1472 - mae: 0.3112 - val_loss: 9.6693 - val_mae: 2.9854\n",
      "Epoch 56/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1629 - mae: 0.3174 - val_loss: 9.6612 - val_mae: 2.9843\n",
      "Epoch 57/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1572 - mae: 0.3061 - val_loss: 9.6615 - val_mae: 2.9849\n",
      "Epoch 58/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1508 - mae: 0.3077 - val_loss: 9.5459 - val_mae: 2.9660\n",
      "Epoch 59/120\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 0.1561 - mae: 0.3099 - val_loss: 9.4787 - val_mae: 2.9564\n",
      "Epoch 60/120\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1364 - mae: 0.2941 - val_loss: 8.9504 - val_mae: 2.8653\n",
      "Epoch 61/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1357 - mae: 0.2926 - val_loss: 8.9777 - val_mae: 2.8708\n",
      "Epoch 62/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1419 - mae: 0.3013 - val_loss: 8.9319 - val_mae: 2.8636\n",
      "Epoch 63/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1329 - mae: 0.2897 - val_loss: 8.7458 - val_mae: 2.8309\n",
      "Epoch 64/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1352 - mae: 0.2918 - val_loss: 8.6260 - val_mae: 2.8095\n",
      "Epoch 65/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1354 - mae: 0.2929 - val_loss: 8.5116 - val_mae: 2.7889\n",
      "Epoch 66/120\n",
      "17/17 [==============================] - 0s 13ms/step - loss: 0.1381 - mae: 0.2906 - val_loss: 8.7037 - val_mae: 2.8238\n",
      "Epoch 67/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1300 - mae: 0.2825 - val_loss: 8.4967 - val_mae: 2.7874\n",
      "Epoch 68/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1404 - mae: 0.2975 - val_loss: 8.5767 - val_mae: 2.8012\n",
      "Epoch 69/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1528 - mae: 0.3067 - val_loss: 8.3638 - val_mae: 2.7635\n",
      "Epoch 70/120\n",
      "17/17 [==============================] - 0s 11ms/step - loss: 0.1433 - mae: 0.2953 - val_loss: 8.2855 - val_mae: 2.7498\n",
      "Epoch 71/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1425 - mae: 0.2942 - val_loss: 8.1962 - val_mae: 2.7327\n",
      "Epoch 72/120\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.1374 - mae: 0.2882 - val_loss: 7.7356 - val_mae: 2.6444\n",
      "Epoch 73/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1361 - mae: 0.2896 - val_loss: 8.0672 - val_mae: 2.7075\n",
      "Epoch 74/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1362 - mae: 0.2891 - val_loss: 7.8355 - val_mae: 2.6640\n",
      "Epoch 75/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1286 - mae: 0.2761 - val_loss: 7.7500 - val_mae: 2.6470\n",
      "Epoch 76/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1335 - mae: 0.2896 - val_loss: 7.7288 - val_mae: 2.6431\n",
      "Epoch 77/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1335 - mae: 0.2945 - val_loss: 7.7032 - val_mae: 2.6372\n",
      "Epoch 78/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1240 - mae: 0.2831 - val_loss: 7.3908 - val_mae: 2.5750\n",
      "Epoch 79/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1255 - mae: 0.2816 - val_loss: 7.2218 - val_mae: 2.5401\n",
      "Epoch 80/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1278 - mae: 0.2852 - val_loss: 6.9643 - val_mae: 2.4863\n",
      "Epoch 81/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1319 - mae: 0.2824 - val_loss: 7.1276 - val_mae: 2.5192\n",
      "Epoch 82/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1288 - mae: 0.2833 - val_loss: 7.3069 - val_mae: 2.5563\n",
      "Epoch 83/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1189 - mae: 0.2766 - val_loss: 6.9327 - val_mae: 2.4755\n",
      "Epoch 84/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1187 - mae: 0.2739 - val_loss: 7.2910 - val_mae: 2.5450\n",
      "Epoch 85/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1271 - mae: 0.2779 - val_loss: 7.1697 - val_mae: 2.5239\n",
      "Epoch 86/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1254 - mae: 0.2747 - val_loss: 7.1701 - val_mae: 2.5223\n",
      "Epoch 87/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1176 - mae: 0.2679 - val_loss: 7.0244 - val_mae: 2.4951\n",
      "Epoch 88/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1122 - mae: 0.2656 - val_loss: 7.0537 - val_mae: 2.5010\n",
      "Epoch 89/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1214 - mae: 0.2732 - val_loss: 6.6589 - val_mae: 2.4149\n",
      "Epoch 90/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1154 - mae: 0.2721 - val_loss: 6.6045 - val_mae: 2.3990\n",
      "Epoch 91/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1224 - mae: 0.2787 - val_loss: 6.5282 - val_mae: 2.3797\n",
      "Epoch 92/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1189 - mae: 0.2653 - val_loss: 6.6082 - val_mae: 2.4020\n",
      "Epoch 93/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1118 - mae: 0.2661 - val_loss: 6.3738 - val_mae: 2.3507\n",
      "Epoch 94/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1159 - mae: 0.2666 - val_loss: 6.4523 - val_mae: 2.3686\n",
      "Epoch 95/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1149 - mae: 0.2709 - val_loss: 6.6702 - val_mae: 2.4094\n",
      "Epoch 96/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1164 - mae: 0.2713 - val_loss: 6.6024 - val_mae: 2.3970\n",
      "Epoch 97/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1082 - mae: 0.2542 - val_loss: 6.7634 - val_mae: 2.4285\n",
      "Epoch 98/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1139 - mae: 0.2676 - val_loss: 6.3737 - val_mae: 2.3462\n",
      "Epoch 99/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1139 - mae: 0.2663 - val_loss: 6.6601 - val_mae: 2.4090\n",
      "Epoch 100/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1097 - mae: 0.2560 - val_loss: 6.6184 - val_mae: 2.3981\n",
      "Epoch 101/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1146 - mae: 0.2659 - val_loss: 6.6461 - val_mae: 2.4051\n",
      "Epoch 102/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1083 - mae: 0.2577 - val_loss: 6.6978 - val_mae: 2.4162\n",
      "Epoch 103/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0921 - mae: 0.2384 - val_loss: 6.6751 - val_mae: 2.4107\n",
      "Epoch 104/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1013 - mae: 0.2481 - val_loss: 6.5909 - val_mae: 2.3944\n",
      "Epoch 105/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1223 - mae: 0.2742 - val_loss: 6.4365 - val_mae: 2.3603\n",
      "Epoch 106/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1037 - mae: 0.2520 - val_loss: 6.4492 - val_mae: 2.3617\n",
      "Epoch 107/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1132 - mae: 0.2645 - val_loss: 6.3572 - val_mae: 2.3428\n",
      "Epoch 108/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1100 - mae: 0.2558 - val_loss: 6.2267 - val_mae: 2.3161\n",
      "Epoch 109/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1001 - mae: 0.2445 - val_loss: 6.2867 - val_mae: 2.3269\n",
      "Epoch 110/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.1151 - mae: 0.2636 - val_loss: 6.3999 - val_mae: 2.3511\n",
      "Epoch 111/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0946 - mae: 0.2433 - val_loss: 6.3475 - val_mae: 2.3417\n",
      "Epoch 112/120\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.1071 - mae: 0.2573 - val_loss: 5.9330 - val_mae: 2.2524\n",
      "Epoch 113/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1054 - mae: 0.2575 - val_loss: 5.9553 - val_mae: 2.2611\n",
      "Epoch 114/120\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.1000 - mae: 0.2527 - val_loss: 5.8971 - val_mae: 2.2449\n",
      "Epoch 115/120\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0965 - mae: 0.2418 - val_loss: 5.9924 - val_mae: 2.2650\n",
      "Epoch 116/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1080 - mae: 0.2538 - val_loss: 6.2140 - val_mae: 2.3163\n",
      "Epoch 117/120\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0971 - mae: 0.2449 - val_loss: 6.0429 - val_mae: 2.2788\n",
      "Epoch 118/120\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.1004 - mae: 0.2523 - val_loss: 6.1360 - val_mae: 2.2995\n",
      "Epoch 119/120\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.1177 - mae: 0.2713 - val_loss: 5.8350 - val_mae: 2.2364\n",
      "Epoch 120/120\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0925 - mae: 0.2357 - val_loss: 5.8486 - val_mae: 2.2356\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x297dba92f08>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model.fit(train,train_label, epochs=120, validation_data=(val,val_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}